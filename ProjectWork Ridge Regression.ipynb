{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bike = pd.read_csv(\"C:/Users/rites/Desktop/5082/hour.csv\")\n",
    "\n",
    "bike_new = bike.drop(['instant', 'dteday', 'casual', 'registered'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(X, prop = [0.6,0.2,0.2], shuffle=False):\n",
    "    df_index = np.arange(X.shape[0])\n",
    "    if shuffle==True:\n",
    "        np.random.shuffle(df_index)\n",
    "    cut1 = int(np.floor(X.shape[0]*prop[0]))\n",
    "    cut2 = int(np.floor(X.shape[0]*(prop[0]+prop[1])))\n",
    "    train_index = df_index[:cut1]\n",
    "    val_index = df_index[cut1:cut2]\n",
    "    test_index = df_index[cut2:]\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_val = X.iloc[val_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    return [X_train, X_val, X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_train, bike_val, bike_test = split(bike_new, [0.6,0.2,0.2])\n",
    "\n",
    "bike_train_X = np.array(bike_train.drop(['cnt'], axis=1))\n",
    "bike_train_Y = np.array(bike_train.loc[:,'cnt'])\n",
    "bike_train_Y.shape = (bike_train_Y.shape[0], 1)\n",
    "\n",
    "bike_val_X = np.array(bike_val.drop(['cnt'], axis=1))\n",
    "bike_val_Y = np.array(bike_val.loc[:,'cnt'])\n",
    "bike_val_Y.shape = (bike_val_Y.shape[0], 1)\n",
    "\n",
    "bike_test_X = np.array(bike_test.drop(['cnt'], axis=1))\n",
    "bike_test_Y = np.array(bike_test.loc[:,'cnt'])\n",
    "bike_test_Y.shape = (bike_test_Y.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ridge_regression(object):\n",
    "    \n",
    "    def __init__(self, alpha, lmda, iterations, intercept):\n",
    "        self.alpha = alpha\n",
    "        self.lmda = lmda\n",
    "        self.iterations = iterations\n",
    "        self.intercept = intercept\n",
    "\n",
    "    def grad_reg(self, X, Y, print_cost=False):\n",
    "        cost_list = []\n",
    "        theta=np.zeros((X.shape[1],1))\n",
    "        if self.intercept == True:\n",
    "            X = np.column_stack((np.ones((X.shape[0],1)), X))\n",
    "            theta=np.zeros((X.shape[1],1))\n",
    "        for i in range(self.iterations):\n",
    "            y_pred = np.dot(X, theta)\n",
    "            theta = theta - 2*self.alpha*np.dot(X.T, (y_pred-Y)) - 2*self.alpha*self.lmda*theta\n",
    "            ridge_loss = self.compute_loss(y_pred, Y, theta)\n",
    "            cost_list.append(ridge_loss)\n",
    "            if print_cost==True:\n",
    "                if i%2000 == 0:\n",
    "                    print(ridge_loss/X.shape[0])\n",
    "        return [cost_list, theta]\n",
    "    \n",
    "    def compute_loss(self, y_pred, y_trn, theta):\n",
    "        loss = np.sum((y_pred-y_trn)**2) + self.lmda*np.sum(theta**2)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, X, theta, intercept= True):\n",
    "        if self.intercept == True:\n",
    "            X = np.column_stack((np.ones((X.shape[0],1)), X))\n",
    "        y_pred = np.round(np.dot(X, theta))\n",
    "        return y_pred\n",
    "    \n",
    "    def RMSE(self, y_pred, y_true):\n",
    "        return np.sqrt(np.mean((y_pred-y_true)**2))\n",
    "    \n",
    "    def MAE(self, y_pred, y_true):\n",
    "        return np.mean(np.abs(y_pred-y_true))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha= 1e-07\n",
      "Train error: 107.501840577\n",
      "Validation error: 185.67127227\n",
      "---------------------------------------\n",
      "alpha= 2e-07\n",
      "Train error: 107.431399555\n",
      "Validation error: 184.792283009\n",
      "---------------------------------------\n",
      "alpha= 3e-07\n",
      "Train error: 107.425512432\n",
      "Validation error: 184.728307945\n",
      "---------------------------------------\n",
      "alpha= 4e-07\n",
      "Train error: 107.427098403\n",
      "Validation error: 184.730573099\n",
      "---------------------------------------\n",
      "alpha= 1e-08\n",
      "Train error: 113.804079726\n",
      "Validation error: 207.059582937\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "for alp in [0.0000001, 0.0000002, 0.0000003, 0.0000004, 0.00000001]:\n",
    "    ridge = ridge_regression(alpha= alp, lmda=0.2, iterations=30000, intercept=True)\n",
    "    _ , theta = ridge.grad_reg(bike_train_X, bike_train_Y)\n",
    "    y_train_pred = ridge.predict(bike_train_X, theta)\n",
    "    y_val_pred = ridge.predict(bike_val_X, theta)\n",
    "    print(\"alpha=\",alp)\n",
    "    print(\"Train error:\", str(ridge.RMSE(y_train_pred, bike_train_Y)))\n",
    "    print(\"Validation error:\", str(ridge.RMSE(y_val_pred, bike_val_Y)))\n",
    "    print(\"---------------------------------------\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= 50\n",
      "Train error: 107.542301891\n",
      "Validation error: 186.265619204\n",
      "---------------------------------------\n",
      "lambda= 25\n",
      "Train error: 107.461931184\n",
      "Validation error: 185.487670923\n",
      "---------------------------------------\n",
      "lambda= 10\n",
      "Train error: 107.433170227\n",
      "Validation error: 185.025452328\n",
      "---------------------------------------\n",
      "lambda= 5\n",
      "Train error: 107.42701136\n",
      "Validation error: 184.883453943\n",
      "---------------------------------------\n",
      "lambda= 1\n",
      "Train error: 107.426646227\n",
      "Validation error: 184.757628998\n",
      "---------------------------------------\n",
      "lambda= 0.1\n",
      "Train error: 107.426179765\n",
      "Validation error: 184.728061104\n",
      "---------------------------------------\n",
      "lambda= 0.2\n",
      "Train error: 107.427098403\n",
      "Validation error: 184.730573099\n",
      "---------------------------------------\n",
      "lambda= 0.01\n",
      "Train error: 107.425956131\n",
      "Validation error: 184.722527742\n",
      "---------------------------------------\n",
      "lambda= 0.001\n",
      "Train error: 107.426138252\n",
      "Validation error: 184.723220006\n",
      "---------------------------------------\n",
      "lambda= 1e-05\n",
      "Train error: 107.426138252\n",
      "Validation error: 184.722646105\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for lmd in [50, 25, 10, 5, 1, 0.1, 0.2, 0.01, 0.001, 0.00001]:\n",
    "    ridge = ridge_regression(alpha= 4e-07, lmda=lmd, iterations=30000, intercept=True)\n",
    "    _ , theta = ridge.grad_reg(bike_train_X, bike_train_Y)\n",
    "    y_train_pred = ridge.predict(bike_train_X, theta)\n",
    "    y_val_pred = ridge.predict(bike_val_X, theta)\n",
    "    print(\"lambda=\",lmd)\n",
    "    print(\"Train error:\", str(ridge.RMSE(y_train_pred, bike_train_Y)))\n",
    "    print(\"Validation error:\", str(ridge.RMSE(y_val_pred, bike_val_Y)))\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda= 1e-05\n",
      "Train error: 107.431309392\n",
      "Validation error: 184.79245348\n",
      "---------------------------------------\n",
      "lambda= 1e-05\n",
      "Train error: 107.427098403\n",
      "Validation error: 184.730573099\n",
      "---------------------------------------\n",
      "lambda= 1e-05\n",
      "Train error: 107.422611379\n",
      "Validation error: 184.737854265\n",
      "---------------------------------------\n",
      "lambda= 1e-05\n",
      "Train error: 107.421940452\n",
      "Validation error: 184.737158942\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for ite in [15000, 30000, 40000, 60000]:\n",
    "    ridge = ridge_regression(alpha= 4e-07, lmda=0.2, iterations=ite, intercept=True)\n",
    "    _ , theta = ridge.grad_reg(bike_train_X, bike_train_Y)\n",
    "    y_train_pred = ridge.predict(bike_train_X, theta)\n",
    "    y_val_pred = ridge.predict(bike_val_X, theta)\n",
    "    print(\"lambda=\",lmd)\n",
    "    print(\"Train error:\", str(ridge.RMSE(y_train_pred, bike_train_Y)))\n",
    "    print(\"Validation error:\", str(ridge.RMSE(y_val_pred, bike_val_Y)))\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39087.1244178\n",
      "12086.8332775\n",
      "11679.4638009\n",
      "11579.8124543\n",
      "11553.5603401\n",
      "11546.0740364\n",
      "11543.6520578\n",
      "11542.7117558\n",
      "11542.264915\n",
      "11542.0139917\n",
      "11541.8564392\n",
      "11541.7503049\n",
      "11541.6752729\n",
      "11541.6201331\n",
      "11541.5781444\n"
     ]
    }
   ],
   "source": [
    "# Optimized hyperparameter values\n",
    "ridge = ridge_regression(alpha= 0.0000004, lmda=0.2, iterations=30000, intercept=True)\n",
    "cost_list, theta = ridge.grad_reg(bike_train_X, bike_train_Y, print_cost=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAERCAYAAACU1LsdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1015675c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cost function as \n",
    "plt.plot(range(30000), cost_list, color='green', marker='.', linestyle='dotted',\n",
    "        linewidth=1, markersize=8)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=30000,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_skl = Ridge(alpha=0.001, max_iter=30000)\n",
    "ridge_skl.fit(X=bike_train_X, y=bike_train_Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train predictions\n",
    "y_train_pred = ridge.predict(bike_train_X, theta)\n",
    "y_train_pred_skl = ridge_skl.predict(X=bike_train_X)\n",
    "\n",
    "# Validation predictions\n",
    "y_val_pred = ridge.predict(bike_val_X, theta)\n",
    "y_val_pred_skl = ridge_skl.predict(X=bike_val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for custom model: 107.426340235\n",
      "Train error for skl model: 107.417888071\n",
      "Validation error for custom model: 184.735040812\n",
      "Validation error for skl model: 184.735750168\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error for custom model:\", str(ridge.RMSE(y_train_pred, bike_train_Y)))\n",
    "print(\"Train error for skl model:\", str(ridge.RMSE(y_train_pred_skl, bike_train_Y)))\n",
    "\n",
    "print(\"Validation error for custom model:\", str(ridge.RMSE(y_val_pred, bike_val_Y)))\n",
    "print(\"Validation error for skl model:\", str(ridge.RMSE(y_val_pred_skl, bike_val_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error for custom model: 187.274444779\n",
      "Test error for skl model: 187.27814907\n"
     ]
    }
   ],
   "source": [
    "# Test predictions\n",
    "y_test_pred = ridge.predict(bike_test_X, theta)\n",
    "y_test_pred_skl = ridge_skl.predict(X=bike_test_X)\n",
    "\n",
    "print(\"Test error for custom model:\", str(ridge.RMSE(y_test_pred, bike_test_Y)))\n",
    "print(\"Test error for skl model:\", str(ridge.RMSE(y_test_pred_skl, bike_test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exaplained variance for custom model: 0.289577681005\n",
      "Exaplained variance for sklearn model: 0.289955149339\n"
     ]
    }
   ],
   "source": [
    "# Explained variance score for custom model\n",
    "print(\"Exaplained variance for custom model: \", end=\"\")\n",
    "print(1 - (np.var(bike_test_Y - y_test_pred)/np.var(bike_test_Y)))\n",
    "# Explained variance score for sklearn model\n",
    "print(\"Exaplained variance for sklearn model: \", end=\"\")\n",
    "print(1 - (np.var(bike_test_Y - y_test_pred_skl)/np.var(bike_test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for skl model: 107.417888071\n",
      "Validation error for skl model: 184.735750168\n",
      "Test error for skl model: 187.27814907\n",
      "Exaplained variance for sklearn model: 0.289955149339\n"
     ]
    }
   ],
   "source": [
    "# Train predictions\n",
    "#y_train_pred = ridge.predict(bike_train_X, theta)\n",
    "y_train_pred_skl = ridge_skl.predict(X=bike_train_X)\n",
    "# Validation predictions\n",
    "#y_val_pred = ridge.predict(bike_val_X, theta)\n",
    "y_val_pred_skl = ridge_skl.predict(X=bike_val_X)\n",
    "print(\"Train error for skl model:\", str(ridge.RMSE(y_train_pred_skl, bike_train_Y)))\n",
    "print(\"Validation error for skl model:\", str(ridge.RMSE(y_val_pred_skl, bike_val_Y)))\n",
    "# Test predictions\n",
    "y_test_pred_skl = ridge_skl.predict(X=bike_test_X)\n",
    "print(\"Test error for skl model:\", str(ridge.RMSE(y_test_pred_skl, bike_test_Y)))\n",
    "# Explained variance score for sklearn model\n",
    "print(\"Exaplained variance for sklearn model: \", end=\"\")\n",
    "print(1 - (np.var(bike_test_Y - y_test_pred_skl)/np.var(bike_test_Y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
